{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruitage par minimisation de la variation totale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des modules et des fonctions de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D discrete gradient \n",
    "def grad(u):\n",
    "    ny,nx = u.shape\n",
    "    Gx = np.zeros(u.shape)\n",
    "    Gy = np.zeros(u.shape)\n",
    "    Gx[:,0:nx-1] = u[:,1:nx] - u[:,0:nx-1]\n",
    "    Gy[0:ny-1,:] = u[1:ny,:] - u[0:ny-1,:]\n",
    "    return Gx,Gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divergence of a 2D discrete field\n",
    "def div(px,py):\n",
    "    ny,nx = px.shape\n",
    "    # process the first component (px) of the input field\n",
    "    div_x = np.zeros(px.shape)\n",
    "    div_x[:,1:nx-1] = px[:,1:nx-1] - px[:,0:nx-2]\n",
    "    div_x[:,0] = px[:,0]\n",
    "    div_x[:,nx-1] = -px[:,nx-2]\n",
    "    # process the second component (py) of the input field\n",
    "    div_y = np.zeros(px.shape)\n",
    "    div_y[1:ny-1,:] = py[1:ny-1,:] - py[0:ny-2,:]\n",
    "    div_y[0,:] = py[0,:]\n",
    "    div_y[ny-1,:] = -py[ny-2,:]\n",
    "    # return output divergence\n",
    "    return div_x + div_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tikhonov based image denoising (see TP 2)\n",
    "def gaussian_denoise(u0,lbda,niter,alpha,Ndisplay=20,video=False):\n",
    "\n",
    "    # initialize local variables\n",
    "    ny,nx = u0.shape\n",
    "    u = np.copy(u0)\n",
    "    gx,gy = grad(u)\n",
    "    E = np.zeros([niter+1,1])\n",
    "    E[0] = np.sum((u-u0)**2 + lbda*(gx**2+gy**2))\n",
    "   \n",
    "    # initialize display (if needed)\n",
    "    if video:\n",
    "        plt.figure(figsize=(7,7))\n",
    "        plt.imshow(u,cmap='gray')\n",
    "        plt.title(\"itération 0: E = %.10e\" % E[0])\n",
    "    \n",
    "    #############\n",
    "    # main loop #\n",
    "    #############\n",
    "    for iter in range(1,niter+1):\n",
    "        \n",
    "        # update image u\n",
    "        g = 2*(u-u0) - 2*lbda*div(gx,gy)\n",
    "        u = u - alpha*g\n",
    "        \n",
    "        # update image gradient\n",
    "        gx,gy = grad(u)\n",
    "        \n",
    "        # compute energy of u\n",
    "        E[iter] = np.sum((u-u0)**2 + lbda*(gx**2+gy**2))\n",
    "        \n",
    "        # update display\n",
    "        if video and (0 == iter%Ndisplay):\n",
    "            plt.imshow(u,cmap='gray')\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(pl.gcf())\n",
    "            plt.title(\"itération %d : E = %.10e\" % (iter,E[iter]))\n",
    "            time.sleep(.1)\n",
    "    \n",
    "    # return outputs\n",
    "    return u,E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : débruitage d’images par minimisation de la variation totale \n",
    "\n",
    "Étant donnée une image bruitée $u_0 : \\Omega\\to\\mathbb{R}$, on s'intéresse au problème\n",
    "de débruitage\n",
    "\n",
    "$\\DeclareMathOperator*{\\argmin}{argmin~}$\n",
    "\\begin{equation}\n",
    "\\overline{u} = \\argmin_{u : \\Omega \\to \\mathbb{R}} \\underset{= E(u)}{\\underbrace{\\frac{1}{2}\\|u-u_0\\|_2^2 + \\lambda \\mathrm{TV}(u)}}\\,,\\qquad (\\mathcal{P})\n",
    "\\end{equation}\n",
    "\n",
    "où $\\lambda > 0$ et\n",
    "$$\\mathrm{TV}(u) = \\displaystyle{\\sum_{(x,y) \\in \\Omega}} \\|(\\nabla u)\n",
    "(x,y)\\|_2\\,.$$\n",
    "\n",
    "\n",
    "On admet que \n",
    "$\\overline{u} = u_0 - \\lambda \\overline{w}$ où $\\overline{w}$ désigne la\n",
    "solution du _problème dual_\n",
    "\n",
    "$$\n",
    "  \\overline{w} = \\argmin_{w \\in \\mathcal{C}} \\frac{1}{2}\\|w - (u_0/\\lambda)\\|_2^2 \\,,\\qquad (\\mathcal{P}^\\star)\n",
    "  %\n",
    "$$\n",
    "\n",
    "où\n",
    "\n",
    "$$\n",
    "  \\mathcal{C} := \\left\\{ -\\mathrm{div}_d(p) ~\\left/~ p : \\Omega\\to \\mathbb{R}^2 \\text{\n",
    "        et } \\max_{(k,\\ell)\\in\\Omega} \\|p(k,\\ell)\\|_2 \\leq 1 \\right.\\right\\}\\,.\n",
    "  %\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-a) Montrer que les problèmes $(\\mathcal{P})$ et $(\\mathcal{P}^\\star)$ admettent chacun une unique solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-b) On admet pour le moment que l'algorithme du gradient projeté appliqué au\n",
    "  problème dual $(\\mathcal{P}^\\star)$ correspond au schéma itératif\n",
    "\n",
    "$$\n",
    "    \\left\\{\n",
    "      \\begin{array}{ccc}\n",
    "        u^n &= &\\lambda \\cdot \\mathrm{div}(p^n) + u_0 \\\\[10pt]\n",
    "        \\forall (k,\\ell) \\in\\Omega\\,,\\quad p^{n+1}(k,\\ell) &= &\\dfrac{p^n(k,\\ell) + \\alpha/\\lambda (\\nabla u^n)(k,\\ell)}{\\max{\\left(1,\\|p^n(k,\\ell) + \\alpha/\\lambda (\\nabla u^n)(k,\\ell)\\|_2\\right)}}\\,,\n",
    "      \\end{array}\n",
    "    \\right.\\qquad(\\mathcal{S})\n",
    "$$\n",
    "\n",
    "Écrire une fonction `tvdenoise(u0,lambda,alpha,niter,...)` permettant d'approcher une solution de $(\\mathcal{P})$ en implémentant ce schéma (renvoyer également en sortie la suite de l'énergie des itérés $(E(u^n))_{n \\geq 0}$ générés par ce schéma.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-c) Tester l'algorithme sur l'image `artifice.tiff` dégradée par un bruit additif blanc gaussien d'écart-type $\\sigma = 20$ avec le réglage $\\alpha = 0.2$ et $\\lambda = 10$. Afficher l'image avant/après débruitage, ainsi que l'évolution de l'énergie au fil des itérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-d) Comparer cet algorithme de débruitage à celui développé lors du TP n$^\\circ$2 (méthode de Tikhonov pour le débruitage gaussien, le code développé en TP2 est rappelé en début de ce TP). \n",
    "\n",
    "**NB** : Afin d'effectuer une comparaison équitable de ces deux algorithmes, vous optimiserez pour chaque algorithme le réglage du paramètre $\\lambda$ afin de minimiser l'écart quadratique entre l'image restaurée et l'image sans bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-e) Quels sont les avantages et inconvénients du débruitage par minimisation de la variation totale par rapport au débruitage par la méthode de Tikhonov (ne pas hésiter à zoomer sur les images)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : construction du schéma dual pour la minimisation de la variation totale\n",
    "\n",
    "\n",
    "Le but de cet exercice est de démontrer que le schéma numérique $(\\mathcal{S})$ proposé en Exercice 1\n",
    "correspond effectivement à un schéma de gradient projeté appliqué au problème\n",
    "dual $(\\mathcal{P}^\\star)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-a) En remarquant que $\\mathcal{C} = - \\mathrm{div}(\\mathcal{B})$ où $\\mathcal{B} = \\left\\{p : \\Omega\\to \\mathbb{R}^2 ~\\left/~ \\max_{(k,\\ell)\\in\\Omega} \\|p(k,\\ell)\\|_2 \\leq 1 \\right.  \\right\\}$, montrer que la solution du problème duale $(\\mathcal{P}^\\star)$ satisfait\n",
    "\n",
    "$$\n",
    "    \\overline{w} = -\\mathrm{div}(\\overline{p}) \\quad \\text{où} \\quad\n",
    "    \\overline{p} = \\argmin_{p \\in \\mathcal{B}} \\frac{1}{2} \\|\\mathrm{div}{(p)} +\n",
    "    (u_0/\\lambda)\\|_2^2\\, \\qquad (\\mathcal{P}')\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-b) En notant $J(p) = \\frac{1}{2} \\|\\mathrm{div}{(p)} + u_0/\\lambda\\|_2^2$ et $\\Pi_{\\mathcal{B}}$ la projection sur le convexe $\\mathcal{B}$, l'algorithme du gradient projeté appliqué au problème $(\\mathcal{P}')$ correspond au schéma itératif\n",
    "\n",
    "$$\n",
    "p^{n+1} = \\Pi_{\\mathcal{B}}(p^n - \\tau \\nabla J(p^n))\n",
    "$$\n",
    "\n",
    "Calculer $\\nabla J(p^n)$ et montrer que le schéma peut s'écrire\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "    %\n",
    "    \\begin{array}{cl}\n",
    "      %\n",
    "      u^n &= \\lambda \\cdot \\mathrm{div}(p^n) + u_0 \\\\\n",
    "      p^{n+1} &= \\Pi_{\\mathcal{B}}\\left(p^n + \\dfrac{\\tau}{\\lambda} \\cdot \\nabla u^n\\right)\n",
    "      %\n",
    "    \\end{array}\n",
    "    %\n",
    "\\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-c) Expliciter $\\Pi_{\\mathcal{B}}$ afin de retrouver le schéma $(\\mathcal{S})$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
